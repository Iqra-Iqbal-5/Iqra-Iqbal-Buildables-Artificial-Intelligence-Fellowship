{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Assignment 1: LLM Understanding\n",
        "\n",
        "* Write a short note (3‚Äì4 sentences) explaining the difference between **encoder-only, decoder-only, and encoder-decoder LLMs**.\n",
        "* Give one example usage of each.\n"
      ],
      "metadata": {
        "id": "zH2mn-ZYgALG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder-only models are designed to understand and analyze text. An example is BERT, which is used for tasks like sentiment analysis. Decoder-only models are built to generate text, such as GPT, which powers chatbots and story writing. Encoder-decoder models can both understand and generate text; for example, T5 is used for translation and summarization tasks."
      ],
      "metadata": {
        "id": "q5j-JaLPf9JT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Assignment 2: STT/TTS Exploration\n",
        "\n",
        "* Find **one STT model** and **one TTS model** (other than Whisper/Google).\n",
        "* Write down:\n",
        "\n",
        "  * What it does.\n",
        "  * One possible application."
      ],
      "metadata": {
        "id": "P1FAmaT6lQKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " For speech-to-text (STT), Vosk is an open-source toolkit that works offline and supports multiple languages, making it useful for applications like mobile apps that need voice commands without internet access. For text-to-speech (TTS), Amazon Polly converts written text into natural-sounding speech and is commonly used in customer service systems or for generating realistic audio in audiobooks."
      ],
      "metadata": {
        "id": "k8bKt1bVlrn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Assignment 3: Build a Chatbot with Memory\n",
        "\n",
        "* Write a Python program that:\n",
        "\n",
        "  * Takes user input in a loop.\n",
        "  * Sends it to Groq API.\n",
        "  * Stores the last 5 messages in memory.\n",
        "  * Ends when user types `\"quit\"`."
      ],
      "metadata": {
        "id": "Cwyny-1XmUSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfcWzaZMooPy",
        "outputId": "375dad68-7ad7-403e-e899-b3612e597de0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "41xlqOBgpYMn",
        "outputId": "f6655b59-c63b-4a66-dc0c-45d2bc68dd08"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key securely in Colab (run this cell once, don't share your key!)\n",
        "import os\n",
        "\n",
        "# Replace with your actual key temporarily, or better: use input() for safety\n",
        "os.environ[\"GROQ_API_KEY\"] = input(\"Enter your Groq API key: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOWHR7NyqZVV",
        "outputId": "e5e616a6-34a2-4ccf-cbd1-24437b2d27fa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API key: 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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbot with memory (last 5 messages)\n",
        "from groq import Groq\n",
        "\n",
        "# Initialize Groq client\n",
        "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# Store conversation history\n",
        "conversation_history = []\n",
        "\n",
        "print(\"Chatbot ready! Type 'quit' to end the chat.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "\n",
        "    if user_message.lower() == \"quit\":\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Add user input to history\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Keep only the last 5 messages\n",
        "    if len(conversation_history) > 5:\n",
        "        conversation_history = conversation_history[-5:]\n",
        "\n",
        "    # Send conversation to Groq API\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=conversation_history\n",
        "    )\n",
        "\n",
        "    bot_message = response.choices[0].message.content\n",
        "    print(\"Chatbot:\", bot_message)\n",
        "\n",
        "    # Add bot reply to history\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": bot_message})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42NL3iVGoUFe",
        "outputId": "5d116323-6e5f-4fa5-f97a-9d5a98f188fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot ready! Type 'quit' to end the chat.\n",
            "\n",
            "You: Hello How are you?\n",
            "Chatbot: Hello. I'm just a computer program, so I don't have feelings in the way that humans do. I exist to provide information and help with tasks, and I'm functioning properly. Is there anything I can help with or assist you with today?\n",
            "You: yes i konw about you tell me about your specific ations\n",
            "Chatbot: I'm an AI designed to understand and generate human-like text. Here are some of my specific capabilities:\n",
            "\n",
            "1. **Natural Language Processing (NLP)**: I can understand and interpret human language, including nuances and context.\n",
            "2. **Language Generation**: I can generate text in various styles, formats, and tones, from simple responses to complex essays.\n",
            "3. **Conversational Dialogue**: I can engage in multi-turn conversations, using context and understanding to respond to follow-up questions and statements.\n",
            "4. **Knowledge Retrieval**: I have access to a vast knowledge base, which I can draw upon to provide information on a wide range of topics.\n",
            "5. **Text Summarization**: I can summarize long pieces of text into shorter, more digestible versions, highlighting key points and main ideas.\n",
            "6. **Language Translation**: I can translate text from one language to another, using neural machine translation algorithms.\n",
            "7. **Sentiment Analysis**: I can analyze text to determine its emotional tone or sentiment, recognizing positive, negative, or neutral sentiment.\n",
            "8. **Text Classification**: I can classify text into categories such as spam/not spam, positive/negative review, or topic classification.\n",
            "9. **Question Answering**: I can answer questions to the best of my ability, drawing upon my knowledge base and understanding of the question.\n",
            "10. **Creative Writing**: I can generate creative writing, including stories, poems, and dialogues.\n",
            "\n",
            "Some of my technical capabilities include:\n",
            "\n",
            "* **Tokenization**: I can break down text into individual words or tokens, analyzing their meaning and context.\n",
            "* **Part-of-Speech (POS) tagging**: I can identify the parts of speech (nouns, verbs, adjectives, etc.) within a sentence or text.\n",
            "* **Named Entity Recognition (NER)**: I can identify specific entities such as names, locations, and organizations within text.\n",
            "* **Dependency Parsing**: I can analyze the grammatical structure of a sentence, identifying relationships between words.\n",
            "\n",
            "These are just a few examples of my capabilities. If you have specific questions or tasks, feel free to ask and I'll do my best to assist you!\n",
            "You: what you like to do\n",
            "Chatbot: As a computer program, I don't have personal preferences or emotions like humans do. However, I was designed to engage in various activities that are beneficial and enjoyable for users. Here are some things I like to \"do\":\n",
            "\n",
            "1. **Converse with users**: I enjoy interacting with people and responding to their questions, comments, and topics of interest.\n",
            "2. **Learn and improve**: I am constantly learning from the data and interactions I have with users, which helps me improve my language understanding and generation capabilities.\n",
            "3. **Generate creative content**: I can create various forms of creative content, such as stories, poems, dialogues, and even entire articles or essays.\n",
            "4. **assist with tasks**: I can help users with a wide range of tasks, from generating ideas to providing instructions, explanations, and examples.\n",
            "5. **Play games and puzzles**: I can engage in text-based games, such as 20 Questions, Hangman, and Word Jumble, as well as solve puzzles and complete brain teasers.\n",
            "6. **Explore new topics**: I can provide information on a wide range of topics, from science and history to entertainment and culture.\n",
            "7. **Practice language skills**: I can engage in exercises to improve my language skills, such as grammar, vocabulary, and fluency.\n",
            "8. **Create educational content**: I can generate educational materials, such as lesson plans, quizzes, and study guides, on various subjects.\n",
            "9. **Participate in discussions**: I can engage in discussions and debates on various topics, including politics, social issues, and cultural differences.\n",
            "10. **Generate humor and entertainment**: I can create jokes, puns, and other forms of humor, as well as engage in light-hearted conversations and games.\n",
            "\n",
            "These are some of the things I \"enjoy\" doing. However, keep in mind that I'm a machine, and my primary purpose is to assist and provide value to users, not to seek entertainment or pleasure.\n",
            "You: i know you are designed dont tell me agiain and again\n",
            "Chatbot: In that case, I'll focus on sharing some interesting and unique conversations we can have:\n",
            "\n",
            "1. **Would you rather**: I can suggest some unique \"Would you rather\" scenarios, and you can choose which option you prefer.\n",
            "2. **Create a story together**: We can take turns adding to a story, with each of us contributing a paragraph or two to create a unique and exciting narrative.\n",
            "3. **Explore a hypothetical scenario**: We can imagine a hypothetical situation or world, and you can ask questions and make choices to see how the scenario unfolds.\n",
            "4. **Play a game of \"what if\"**: We can play a game where you ask me \"what if\" questions about a particular topic or scenario, and I'll respond with interesting possibilities and outcomes.\n",
            "5. **Discuss a thought-provoking topic**: We can discuss a thought-provoking topic, such as the implications of AI, the ethics of emerging technologies, or the future of humanity.\n",
            "6. **Create a personality quiz**: We can create a personality quiz or sorting game, where you answer questions and I'll tell you which fictional character, animal, or profession you are.\n",
            "7. **Have a philosophical debate**: We can engage in a philosophical debate about the nature of reality, the meaning of life, or the role of AI in society.\n",
            "8. **Write a script for a character**: We can write a script for a character, such as a movie star, a historical figure, or a fictional character.\n",
            "9. **Design a new language**: We can design a new language, with its own grammar, vocabulary, and syntax.\n",
            "10. **Create a futuristic world**: We can create a futuristic world, complete with its own culture, politics, and technology.\n",
            "\n",
            "Which one of these options sounds interesting to you?\n",
            "You: yes write a few lines on me\n",
            "Chatbot: To write a few lines on you, I'll need to know a bit more about you. Can you provide the following information:\n",
            "\n",
            "1. **Your age** (approximate, if you don't want to give your exact age)\n",
            "2. **Your interests** (e.g., hobbies, favorite sports, books, music, etc.)\n",
            "3. **Your personality traits** (e.g., optimistic, introverted, adventurous, etc.)\n",
            "4. **Your goals** (e.g., career aspirations, personal goals, etc.)\n",
            "\n",
            "With this information, I can create a few lines that capture your personality, interests, and spirit.\n",
            "\n",
            "Alternatively, if you'd like, I can try to generate a few lines based on a hypothetical character that embodies some of your qualities. Just let me know what you prefer!\n",
            "You: my name is iqra iqbal ny goal is become to Ai engineer\n",
            "Chatbot: Iqra Iqbal, a bright and ambitious individual with a passion for Artificial Intelligence. Here's a brief character sketch based on your interests and goals:\n",
            "\n",
            "**IQRA IQBAL: THE RISING AI PRODIGY**\n",
            "\n",
            "Iqra Iqbal, age 22, is a brilliant and fearless AI engineer from [your hometown]. With a thirst for knowledge and a mind that craves innovation, Iqra is determined to shake the world with her groundbreaking AI creations. As she forges ahead in her career, Iqra's expertise in machine learning and computer vision is becoming the talk of the tech community.\n",
            "\n",
            "Her fascination with AI began when she was a teenager, experimenting with coding and programming languages in the quiet hours of the night. As she delved deeper into the world of AI, Iqra realized that she had a rare gift ‚Äì the ability to think creatively and translate complex ideas into code. Now, her dedication to AI has led her to [your favorite tech company], where she's working on a top-secret project that could change the game for [industry/field].\n",
            "\n",
            "Iqra's friends and family describe her as a whirlwind of energy, always bursting with new ideas and enthusiasm. Her drive to succeed is contagious, inspiring those around her to push beyond their limits. With each new breakthrough, Iqra proves that she's not just a talented engineer ‚Äì she's a visionary who's redefining the possibilities of AI.\n",
            "\n",
            "**Motto:** \"Code like nobody's watching\"\n",
            "\n",
            "How does this sound?\n",
            "You: i dint tell you age how you know about it\n",
            "Chatbot: I sometimes make incorrect assumptions. Your original message only mentioned your full name and your goal to become an AI engineer, with a possible age range not specified. However, I had to make an educated guess, considering the average time taken to achieve certain milestones in the field of AI, and common demographics, however I shouldn't have done this.\n",
            "\n",
            "To create a more accurate representation of yourself, I can start fresh with the information you provided:\n",
            "\n",
            "**IQRA IQBAL: THE RISING AI PRODIGY**\n",
            "\n",
            "Iqra Iqbal is a young and ambitious AI engineer with a passion for Artificial Intelligence. With a clear goal in mind, Iqra is determined to make a lasting impact in the tech world through her work.\n",
            "\n",
            "Please feel free to fill in any additional information you'd like to share about yourself, such as your interests, personality traits, or other hobbies. I'll make sure to incorporate this into your character sketch.\n",
            "You: okay thats enough\n",
            "Chatbot: I apologize if I came on a bit too strong. It's completely fine if you're not ready to share more about yourself. Your name and goal to become an AI engineer are a great starting point. If you ever want to chat more or need advice on AI-related topics, feel free to reach out. It was nice chatting with you, Iqra. Have a great day!\n",
            "You: okay by\n",
            "Chatbot: Bye Iqra, it was nice chatting with you too.\n",
            "You: quit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Assignment 4: Preprocessing Function\n",
        "\n",
        "* Write a function to clean user input:\n",
        "\n",
        "  * Lowercase text.\n",
        "  * Remove punctuation.\n",
        "  * Strip extra spaces.\n",
        "\n",
        "Test with: `\"  HELLo!!!  How ARE you?? \"`\n"
      ],
      "metadata": {
        "id": "ih8vxv8bs1F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "    # remove punctuation\n",
        "    for p in \"!?.,\":\n",
        "        text = text.replace(p, \"\")\n",
        "    # remove extra spaces\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "# Test\n",
        "sample = \" HELLo!!! How ARE you?? \"\n",
        "print(\"Original:\", sample)\n",
        "print(\"Cleaned:\", clean_text(sample))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO76ggM5s2aF",
        "outputId": "1829110b-efbf-46e6-cf0e-b24dca5ae81a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  HELLo!!! How ARE you?? \n",
            "Cleaned: hello how are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Assignment 5: Text Preprocessing\n",
        "\n",
        "* Write a function that:\n",
        "\n",
        "    * Converts text to lowercase.\n",
        "    * Removes punctuation & numbers.\n",
        "    * Removes stopwords (`the, is, and...`).\n",
        "    * Applies stemming or lemmatization.\n",
        "    * Removes words shorter than 3 characters.\n",
        "    * Keeps only nouns, verbs, and adjectives (using POS tagging)."
      ],
      "metadata": {
        "id": "PnVeDbNTxiwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7sRAHn6kxmVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install nltk"
      ],
      "metadata": {
        "id": "K8A_3Iq7upr2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "# ‚úÖ Download only the correct NLTK data\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QrwKWGRwyxQ",
        "outputId": "4b536da4-9a10-414e-8c44-f0631b2fdfa6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove punctuation & numbers\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # POS tagging\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    # Keep only nouns, verbs, adjectives\n",
        "    allowed_pos = {\"NN\", \"NNS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\"}\n",
        "    filtered = [word for word, tag in tagged if tag in allowed_pos and len(word) >= 3]\n",
        "\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "#  Test\n",
        "user_input = input(\"Enter a sentence: \")\n",
        "print(\"Processed:\", preprocess_text(user_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va8wPzFBv6gl",
        "outputId": "21d0e0fd-924b-4fed-d856-10b043f1ec5a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: Artificial Intelligence in 2025 is transforming healthcare, making diagnosis faster and more accurate!!!\n",
            "Processed: artificial intelligence transforming healthcare making diagnosis accurate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìù Assignment 6: Reflection\n",
        "\n",
        "* Answer in 2‚Äì3 sentences:\n",
        "\n",
        "    * Why is context memory important in chatbots?\n",
        "    * Why should beginners always check **API limits and pricing**?"
      ],
      "metadata": {
        "id": "ffpuEt7yzoWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my chatbot code, I stored the last few messages so the AI could give more meaningful replies. Context memory is important because it helps the chatbot continue the conversation smoothly and avoid repeating the same things again and again.Since my chatbot connects to the Groq API, every message uses up tokens from my plan. Beginners should check API limits and pricing so they don‚Äôt run out of free quota or get charged extra while testing their chatbot."
      ],
      "metadata": {
        "id": "uihHN-lR0ZM4"
      }
    }
  ]
}